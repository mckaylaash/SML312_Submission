{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stock  week                                            comment  timestamp  \\\n",
      "0   MMM     1  welcome to rstocks for beginner advice brokera...        NaN   \n",
      "1   MMM     1  lawsuits scare me away from them i know you me...        NaN   \n",
      "2   MMM     1  be greedy when others are fearful the lawsuits...        NaN   \n",
      "3   MMM     1      i just did a little trend analysis of it here        NaN   \n",
      "4   MMM     1  3m is a good blue chip company dont expect to ...        NaN   \n",
      "\n",
      "   upvotes  author                                    comment_cleaned  \\\n",
      "0      NaN     NaN  welcome to rstock for beginner advice brokerag...   \n",
      "1      NaN     NaN  lawsuit scare I away from they I know you ment...   \n",
      "2      NaN     NaN  be greedy when other be fearful the lawsuit wi...   \n",
      "3      NaN     NaN       I just do a little trend analysis of it here   \n",
      "4      NaN     NaN  3 m be a good blue chip company do not expect ...   \n",
      "\n",
      "                                      keywords  \n",
      "0  [all, it, info, way, low, any, top, see, a]  \n",
      "1                         [me, it, fine, cash]  \n",
      "2                                     [are, a]  \n",
      "3                                      [it, a]  \n",
      "4                     [good, are, blue, it, a]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Need to compile a list of keywords and tags the scraper will search \n",
    "# through. Want to flag any stock tickers, as well as general phrases\n",
    "# that indicate sentiment about the market performance. Compiling list\n",
    "# of stock symbols from S&P 500 and NASDAQ data\n",
    "\n",
    "# Source: https://github.com/datasets/nasdaq-listings/blob/main/data/nasdaq-listed.csv\n",
    "nasdaq = pd.read_csv('/Users/mckaylaashley/Downloads/nasdaq-listed.csv')\n",
    "nasdaq = nasdaq['Symbol'].tolist()\n",
    "\n",
    "# Source: https://gist.github.com/ZeccaLehn/f6a2613b24c393821f81c0c1d23d4192\n",
    "sp500 = pd.read_csv('/Users/mckaylaashley/Downloads/SP500.csv')\n",
    "sp500 = sp500['Symbol'].tolist()\n",
    "\n",
    "terms = ['bull', 'bear', 'crash', 'recession', 'recovery']\n",
    "\n",
    "# Combine all terms into one\n",
    "full_list = list(sp500 + nasdaq + terms)\n",
    "full_list = [str(keyword) for keyword in full_list if isinstance(keyword, (str, int, float))]\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('finalfinal_dataset.csv')\n",
    "\n",
    "# Compile the regex for matching keywords in full_list\n",
    "keyword_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in full_list) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Function to clean and match stocks\n",
    "def match_keywords(comment_text):\n",
    "    # Check if the comment is a string\n",
    "    if not isinstance(comment_text, str):\n",
    "        return []\n",
    "    \n",
    "    # Match keywords in the comment\n",
    "    matches = keyword_pattern.findall(comment_text)\n",
    "    return list(set(matches))  # Remove duplicates\n",
    "\n",
    "# Filter and clean comments\n",
    "df['keywords'] = df['comment'].apply(match_keywords)  # Extract keywords\n",
    "filtered_df = df[df['keywords'].str.len() > 0]  # Filter rows with at least one match\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV (optional)\n",
    "filtered_df.to_csv('finfiltered_comments.csv', index=False)\n",
    "\n",
    "# Preview the filtered DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year       Type of Graph Ticker      Industry  Degree  Weighted Degree  \\\n",
      "0  2022  Top 200 Industries   TSLA  Unclassified     199          8705176   \n",
      "1  2022  Top 200 Industries   AAPL         Comps     199          7973116   \n",
      "2  2022  Top 200 Industries   AMZN         BusSv     199          6002188   \n",
      "3  2022  Top 200 Industries   META         BusSv     199          4915119   \n",
      "4  2022  Top 200 Industries   MSFT         BusSv     199          4374581   \n",
      "\n",
      "   Eccentricity  Closness Centrality  Harmonic Closness Centrality  \\\n",
      "0             1                  1.0                           1.0   \n",
      "1             1                  1.0                           1.0   \n",
      "2             1                  1.0                           1.0   \n",
      "3             1                  1.0                           1.0   \n",
      "4             1                  1.0                           1.0   \n",
      "\n",
      "   Betweeness Centrality  Eigen Centrality  \n",
      "0                2.38157               1.0  \n",
      "1                2.38157               1.0  \n",
      "2                2.38157               1.0  \n",
      "3                2.38157               1.0  \n",
      "4                2.38157               1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alguindy = pd.read_csv('/Users/mckaylaashley/Downloads/Top200_2022.csv')\n",
    "print(alguindy.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonspec_tickers = {\n",
    "    'TSLA': 'Tesla',\n",
    "    'AAPL': 'Apple',\n",
    "    'AMZN': 'Amazon',\n",
    "    'META': 'Meta',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'AMC': 'AMC Entertainment',\n",
    "    'GOOGL': 'Google',\n",
    "    'NVDA': 'NVIDIA',\n",
    "    'NFLX': 'Netflix',\n",
    "    'GME': 'GameStop',\n",
    "    'TWTR': 'Twitter',\n",
    "    'AAL': 'American Airlines',\n",
    "    'ROKU': 'Roku',\n",
    "    'PYPL': 'PayPal Holdings, ',\n",
    "    'SNAP': 'Snap Inc',\n",
    "    'DAL': 'Delta Air',\n",
    "    'SQ': 'Block',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'DKNG': 'DraftKings',\n",
    "    'MRNA': 'Moderna',\n",
    "    'INTC': 'Intel Corp',\n",
    "    'PENN': 'Penn National Gaming',\n",
    "    'NKLA': 'Nikola',\n",
    "    'WMT': 'Walmart',\n",
    "    'LCID': 'Lucid Group',\n",
    "    'XOM': 'Exxon',\n",
    "    'INO': 'Inovio',\n",
    "    'BBIG': 'Vinco Ventures',\n",
    "    'CRM': 'Salesforce',\n",
    "    'PLTR': 'Palantir',\n",
    "    'PTON': 'Peloton',\n",
    "    'OXY': 'Occidental Petroleum',\n",
    "    'GM': 'General Motors',\n",
    "    'DWAC': 'Digital World Acquisition',\n",
    "    'ADBE': 'Adobe',\n",
    "    'BYND': 'Beyond Meat',\n",
    "    'JNJ': 'Johnson & Johnson',\n",
    "    'PFE': 'Pfizer',\n",
    "    'MULN': 'Mullen',\n",
    "    'KO': 'Coca-Cola',\n",
    "    'GNUS': 'Genius Brands',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'ZM': 'Zoom',\n",
    "    'SOFI': 'SoFi',\n",
    "    'NKE': 'Nike',\n",
    "    'LUV': 'Southwest',\n",
    "    'TLRY': 'Tilray',\n",
    "    'SPCE': 'Virgin Galactic',\n",
    "    'MGM': 'MGM Resorts',\n",
    "    'UBER': 'Uber'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of specific tickers to company names\n",
    "spec_tickers = {\n",
    "    'T': 'AT&T.',\n",
    "    'MA': 'Mastercard',\n",
    "    'ES': 'Eversource Energy',\n",
    "    'M': 'Macy',\n",
    "    'W': 'Wayfair.',\n",
    "    'NET': 'Cloudflare.',\n",
    "    'EA': 'Electronic Arts',\n",
    "    'U': 'Unity Software',\n",
    "    'X': 'United States Steel',\n",
    "    'GS': 'Goldman',\n",
    "    'ON': 'ON Semiconductor',\n",
    "    'MO': 'Altria ',\n",
    "    'A': 'Agilent Technologies',\n",
    "    'BA': 'Boeing',\n",
    "    'F': 'Ford Motor',\n",
    "    'DIS': 'Disney',\n",
    "    'BAC': 'Bank of America',\n",
    "    'V': 'Visa',\n",
    "     'UAL': 'United Airlines',\n",
    "    'PLUG': 'Plug Power',\n",
    "    'AMD': 'Advanced Micro Devices',\n",
    "    'HD': 'Home Depot',\n",
    "    'COST': 'Costco',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment       matched_tickers\n",
      "19  i looked at our purchase orders for our it and...                [MSFT]\n",
      "21  are you pricing in their lawsuits i wonder if ...                 [JNJ]\n",
      "38  it depends on your time horizon but you have a...  [WFC, SOFI, V, AAPL]\n",
      "39  look at this video dalio is a big advocate on ...                 [DAL]\n",
      "41  pretty much all large cap tech at this point h...                  [MO]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('finfiltered_comments.csv')\n",
    "\n",
    "all_tickers = {**spec_tickers, **nonspec_tickers}\n",
    "\n",
    "def match_keywords(comment_text):\n",
    "    if not isinstance(comment_text, str):\n",
    "        return []\n",
    "\n",
    "    matched_tickers = []\n",
    "\n",
    "    for ticker, company in spec_tickers.items():\n",
    "        if company.lower() in comment_text.lower():\n",
    "            matched_tickers.append(ticker)\n",
    "\n",
    "    for ticker, company in nonspec_tickers.items():\n",
    "        if ticker.lower() in comment_text.lower() or company.lower() in comment_text.lower():\n",
    "            matched_tickers.append(ticker)\n",
    "\n",
    "    return list(set(matched_tickers))\n",
    "\n",
    "\n",
    "df['matched_tickers'] = df['comment'].apply(match_keywords)\n",
    "\n",
    "filtered_df = df[df['matched_tickers'].str.len() > 0]\n",
    "\n",
    "filtered_df.to_csv('filtered_by_alguindy_tickers.csv', index=False)\n",
    "\n",
    "filfilter_df = filtered_df\n",
    "\n",
    "finfilter_df = filtered_df.drop(columns=['stock', 'timestamp', 'upvotes', 'author'])\n",
    "finfilter_df.to_csv('finfiltered_by_alguindy_tickers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_comments = finfilter_df[finfilter_df.duplicated(subset='comment', keep=False)]\n",
    "df_cleaned = finfilter_df.drop_duplicates(subset='comment', keep='first')  # Keeps the first occurrence\n",
    "df_cleaned.to_csv('final_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
